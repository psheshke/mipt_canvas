{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISV_j8bo9if8"
   },
   "source": [
    "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n",
    "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnuMlpJp9if9"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lkoop-MT9if-"
   },
   "source": [
    "<h2 style=\"text-align: center;\"><b>Нейрон с сигмодой</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qGKppuWS9if-"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6gfbXqXQ9if_"
   },
   "source": [
    "### Сначала необходимо решить ноутбук `[seminar]perceptron.ipynb`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IUjxg_IS31tn"
   },
   "source": [
    "В данном задании Вам нужно будет: \n",
    "- самостоятельно реализовать класс **`Neuron()`** с сигмоидальной функцией активации\n",
    "- обучить и протестировать этот класс на сгенерированных и реальных данных (файлы с реальными данными помещены в папку /data в этой же директории)\n",
    "- сравнить качество работы Вашего класса с классом из библиотеки `scikit-learn` (`sklearn.linear_model.Perceptron()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHap62ES9igB"
   },
   "source": [
    "В данном ноутбуке Вам предстоит реализовать нейрон с разными функциями активации: Sigmoid, ReLU, LeakyReLU и ELU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-OYlV519igB"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap  # тут лежат разные штуки для цветовой магии\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OU1KkHre9igF"
   },
   "source": [
    "Напомним, что **сигмоидальная функция (сигмоида)** выглядит так:  \n",
    "    \n",
    "$$\\sigma(x)=\\frac{1}{1+e^{-z}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sG06ukL831t-"
   },
   "source": [
    "Её график:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I8-Pa5CL31uD"
   },
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1200/1*IDAnCFoeXqWL7F4u9MLossMtA.png\" width=500px height=350px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w3B2wpFb31uH"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ygSraLzH31uJ"
   },
   "source": [
    "**Упражнение 1**\n",
    "\n",
    "Посчитать производную этой функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CmEexUY631uM"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgpFOaPm9igG"
   },
   "source": [
    "В данном случае мы снова решаем задачу бинарной классификации (2 класса: 1 или 0), но здесь уже будет другая функция активации:\n",
    "\n",
    "$$\n",
    "Loss(\\hat{y}, y) = \\frac{1}{2n}\\sum_{i=1}^{n} (\\hat{y_i} - y_i)^2 = \\frac{1}{2n}\\sum_{i=1}^{n} (\\sigma(w \\cdot X_i) - y_i)^2\n",
    "$$  \n",
    "\n",
    "Здесь $w \\cdot X_i$ - скалярное произведение, а $\\sigma(w \\cdot X_i) =\\frac{1}{1+e^{-w \\cdot X_i}} $ - сигмоида ($i$ -- номер объекта в выборке).  \n",
    "\n",
    "**Примечание:** Здесь предполагается, что $b$ - свободный член - является частью вектора весов: $w_0$. Тогда, если к $X$ приписать единичный столбец, в скалярном произведении $b$ будет именно как свободный член."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KUp-NwTw9igG"
   },
   "source": [
    "Формула для обновления весов при градиентном спуске будет такая:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IOqEcXvl9igH"
   },
   "source": [
    "$$ \\frac{\\partial Loss}{\\partial w} = \\frac{1}{n} (\\sigma(w \\cdot X) - y)\\sigma(w \\cdot X)(1 - \\sigma(w \\cdot X))X$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r1kKhH1v9igI"
   },
   "source": [
    "Реализуйте сигмоиду и её производную:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCgAeho19igI"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"Сигмоидальная функция\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nXwsy-7J9igL"
   },
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    \"\"\"Производная сигмоиды\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKurn-7F9igN"
   },
   "source": [
    "Теперь нужно написать нейрон с сигмоидной функцией активации. Здесь всё очень похоже на перцептрон, но будут по-другому обновляться веса и другая функция активации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 610,
     "status": "error",
     "timestamp": 1539422231000,
     "user": {
      "displayName": "Григорий Лелейтнер",
      "photoUrl": "",
      "userId": "07179937308049589303"
     },
     "user_tz": -300
    },
    "id": "AM9vn3OX9igO",
    "outputId": "0391ccb7-3655-4637-e1eb-314d67b164e4"
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, w=None, b=0):\n",
    "        \"\"\"\n",
    "        :param: w -- вектор весов\n",
    "        :param: b -- смещение\n",
    "        \"\"\"\n",
    "        # Пока что мы не знаем размер матрицы X, а значит не знаем, сколько будет весов\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def activate(self, x):\n",
    "        return # Ваш код здесь\n",
    "        \n",
    "    def forward_pass(self, X):\n",
    "        \"\"\"\n",
    "        Рассчитывает ответ перцептрона при предъявлении набора объектов\n",
    "        :param: X -- матрица примеров размера (n, m), каждая строка - отдельный объект\n",
    "        :return: вектор размера (n, 1) из нулей и единиц с ответами перцептрона \n",
    "        \"\"\"\n",
    "        n = X.shape[0]\n",
    "        y_pred = np.zeros((n, 1))  # y_pred(icted) - предсказанные классы\n",
    "        # Ваш код здесь\n",
    "        return y_pred\n",
    "    \n",
    "    def backward_pass(self, X, y, y_pred, learning_rate=0.005):\n",
    "        \"\"\"\n",
    "        Обновляет значения весов перцептрона в соответствии с этим объектом\n",
    "        :param: X -- матрица входов размера (n, m)\n",
    "                y -- вектор правильных ответов размера (n, 1)\n",
    "                learning_rate - \"скорость обучения\" (символ alpha в формулах выше)\n",
    "        В этом методе ничего возвращать не нужно, только правильно поменять веса\n",
    "        с помощью градиентного спуска.\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "    \n",
    "    def fit(self, X, y, num_epochs=300):\n",
    "        \"\"\"\n",
    "        Спускаемся в минимум\n",
    "        :param: X -- матрица объектов размера (n, m)\n",
    "                y -- вектор правильных ответов размера (n, 1)\n",
    "                num_epochs -- количество итераций обучения\n",
    "        :return: losses -- вектор значений функции потерь\n",
    "        \"\"\"\n",
    "        self.w = np.zeros((X.shape[1], 1))  # столбец (m, 1)\n",
    "        self.b = 0  # смещение\n",
    "        losses = []  # значения функции потерь на различных итерациях обновления весов\n",
    "        \n",
    "        for i in range(num_epochs):\n",
    "            # Ваш код здесь\n",
    "        \n",
    "        return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thtFp-at9igS"
   },
   "source": [
    "### Тестирование нейрона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hOuYzf_u9igS"
   },
   "source": [
    "Здесь Вам нужно самим протестировать новый нейрон **на тех же данных (\"Яблоки и Груши\")** по аналогии с тем, как это было проделано с перцептроном  (можете смело копировать код, только будьте осторожны - кое-что в нём всё же скорее всего придётся поправить).\n",
    "В итоге нужно вывести: \n",
    "* график, на котором будет показано, как изменяется функция потерь $Loss$ в зависимости от числа итераций обучения\n",
    "* график с раскраской выборки сигмоидальным нейроном"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JGs_F5N331u9"
   },
   "source": [
    "**Проверка forward_pass()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 660,
     "status": "error",
     "timestamp": 1539421983029,
     "user": {
      "displayName": "Григорий Лелейтнер",
      "photoUrl": "",
      "userId": "07179937308049589303"
     },
     "user_tz": -300
    },
    "id": "aKmrhe_831vG",
    "outputId": "0bc0b4ae-084b-463e-9602-76f2cd17a260"
   },
   "outputs": [],
   "source": [
    "w = np.array([1., 2.]).reshape(2, 1)\n",
    "b = 2.\n",
    "X = np.array([[1., 3.],\n",
    "              [2., 4.],\n",
    "              [-1., -3.2]])\n",
    "\n",
    "neuron = Neuron(w, b)\n",
    "y_pred = neuron.forward_pass(X)\n",
    "print (\"y_pred = \" + str(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZWjbXaT431vN"
   },
   "source": [
    "|Должно быть||\n",
    "|------|-------|\n",
    "|**y_pred**|[0.99987661, 0.99999386,0.00449627]|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYG2uFcy31vP"
   },
   "source": [
    "**Проверка backward_pass()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvUkrgQy31vQ"
   },
   "outputs": [],
   "source": [
    "y = np.array([1, 0, 1]).reshape(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 577,
     "status": "error",
     "timestamp": 1539421988792,
     "user": {
      "displayName": "Григорий Лелейтнер",
      "photoUrl": "",
      "userId": "07179937308049589303"
     },
     "user_tz": -300
    },
    "id": "pWooOLya31vX",
    "outputId": "cd2b2358-b615-4413-e984-0966ede7f355"
   },
   "outputs": [],
   "source": [
    "neuron.backward_pass(X, y, y_pred)\n",
    "\n",
    "print (\"w = \" + str(neuron.w))\n",
    "print (\"b = \" + str(neuron.b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DcVff1Is31vc"
   },
   "source": [
    "|Должно быть||\n",
    "|------|-------|\n",
    "|**w**|[0.99985106, 1.99952388]|\n",
    "|**b**|2.000148326741343|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWgwECpD9igT"
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь (можете использовать много ячеек)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-PfNPtrZ31vq"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iT8so51w31wD"
   },
   "source": [
    "В **домашнем задании** вам нужно будет реализовать класс `Neuron()` с другими функциями активации: ReLu, LeakyReLU, ELU, SeLU, Swish (какими-то из них), в тесте будут проверяться веса и значения функции потерь при некотором количестве итераций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yhGNsWPQ9igf"
   },
   "source": [
    "<h3 style=\"text-align: center;\"><b>Полезные ссылки</b></h3>\n",
    "\n",
    "0). Обязательно прочитайте (если вам позволяет английский) эту статью от Стэнфорда: http://cs231n.github.io/neural-networks-1/\n",
    "\n",
    "1). Хорошая статья про функции активации: https://www.jeremyjordan.me/neural-networks-activation-functions/\n",
    "\n",
    "2). [Видео от Siraj Raval](https://www.youtube.com/watch?v=-7scQpLossT7uo)\n",
    "\n",
    "3). Современная статья про функции активации. Теперь на хайпе активация $swish(x) = x\\sigma (\\beta x)$: https://arxiv.org/pdf/1710.05941.pdf (кстати, при её поиске в некоторой степени использовался neural architecture search)\n",
    "\n",
    "4). SeLU имеет очень интересные, доказанные с помощью теории вероятностей свойства: https://arxiv.org/pdf/1706.02515.pdf (да, в этой статье 102 страницы)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[seminar]neuron.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
