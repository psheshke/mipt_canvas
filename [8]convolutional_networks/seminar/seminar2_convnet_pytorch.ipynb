{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hoxBEVcAmvQF"
   },
   "source": [
    "<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" style=\"height:90px;\" width=500/></p>\n",
    "\n",
    "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fqKI3PvQqk-x"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Q6NgIGBmvQH"
   },
   "source": [
    "В этом ноутбке мы научимся писать свои свёрточные нейросети на фреймворке PyTorch, и протестируем их работу на датасетах MNIST и CIFAR10. \n",
    "\n",
    "**ВНИМАНИЕ:** Рассматривается ***задача классификации изображений***.\n",
    "\n",
    "(Подразумевается, что читатель уже знаком с многослойной нейроннной сетью).  \n",
    "\n",
    "***Свёрточная нейросеть (Convolutional Neural Network, CNN)*** - это многослойная нейросеть, имеющая в своей архитектуре помимо *полносвязных слоёв* (а иногда их может и не быть) ещё и **свёрточные слои (Conv Layers)** и **pooling-слои (Pool Layers)**.  \n",
    "\n",
    "Собственно, название такое эти сети получили потому, что в основе их работы лежит операция **свёртки**. \n",
    "\n",
    "\n",
    "Сразу же стоит сказать, что свёрточные нейросети **были придуманы прежде всего для задач, связанных с картинками**, следовательно, на вход они тоже \"ожидают\" картинку.\n",
    "\n",
    "Расмотрим их устройство более подробно:\n",
    "\n",
    "* Вот так выглядит неглубокая свёрточная нейросеть, имеющая такую архитектуру:  \n",
    "`Input -> Conv 5x5 -> Pool 2x2 -> Conv 5x5 -> Pool 2x2 -> FC -> Output`\n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/269e3903f62eb2c4d13ac4c9ab979510010f8968/68747470733a2f2f7261772e6769746875622e636f6d2f746176677265656e2f6c616e647573655f636c617373696669636174696f6e2f6d61737465722f66696c652f636e6e2e706e673f7261773d74727565\" width=800, height=600>\n",
    "\n",
    "Свёрточные нейросети (обыкновенные, есть и намного более продвинутые) почти всегда строятся по следующему правилу:  \n",
    "\n",
    "`INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC`  \n",
    "\n",
    "то есть:  \n",
    "\n",
    "1). ***Входной слой*** (batch картинок `HxWxC`)  \n",
    "\n",
    "2). $M$ блоков (M $\\ge$ 0) из свёрток и pooling-ов, причём именно в том порядке, как в формуле выше. Все эти $M$ блоков вместе называют ***feature extractor*** свёрточной нейросети, потому что эта часть сети отвечает непосредственно за формирование новых, более сложных признаков, поверх тех, которые подаются (то есть, по аналогии с MLP, мы опять же переходим к новому признаковому пространству, однако здесь оно строится сложнее, чтем в обычных многослойных сетях, поскольку используется операция свёртки)  \n",
    "\n",
    "3). $K$ штук FullyConnected-слоёв (с активациями). Эту часть из $K$ FC-слоёв называют ***classificator***, поскольку эти слои отвечают непосредственно за предсказание нужно класса (сейчас рассматривается задача классификации изображений)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUh08RELmvQI"
   },
   "source": [
    "\n",
    "<h3 style=\"text-align: center;\"><b>Свёрточная нейросеть на PyTorch</b></h3>\n",
    "\n",
    "Ешё раз напомним про основные компоненты нейросети:\n",
    "\n",
    "- непосредственно, сама **архитектура** нейросети (сюда входят типы функций активации у каждого нейрона);\n",
    "- начальная **инициализация** весов каждого слоя;\n",
    "- метод **оптимизации** нейросети (сюда ещё входит метод изменения `learning_rate`);\n",
    "- размер **батчей** (`batch_size`);\n",
    "- количетсво итераций обучения (`num_epochs`);\n",
    "- **функция потерь** (`loss`);  \n",
    "- тип **регуляризации** нейросети (для каждого слоя можно свой);  \n",
    "\n",
    "То, что связано с ***данными и задачей***:  \n",
    "- само **качество** выборки (непротиворечивость, чистота, корректность постановки задачи);  \n",
    "- **размер** выборки;  \n",
    "\n",
    "Так как мы сейчас рассматриваем **архитектуру CNN**, то, помимо этих компонент, в свёрточной нейросети можно настроить следующие вещи:  \n",
    "\n",
    "- (в каждом ConvLayer) **размер фильтров (окна свёртки)** (`kernel_size`)\n",
    "- (в каждом ConvLayer) **количество фильтров** (`out_channels`)  \n",
    "- (в каждом ConvLayer) размер **шага окна свёртки (stride)** (`stride`)  \n",
    "- (в каждом ConvLayer) **тип padding'а** (`padding`)  \n",
    "\n",
    "\n",
    "- (в каждом PoolLayer) **размер окна pooling'a** (`kernel_size`)  \n",
    "- (в каждом PoolLayer) **шаг окна pooling'а** (`stride`)  \n",
    "- (в каждом PoolLayer) **тип pooling'а** (`pool_type`)  \n",
    "- (в каждом PoolLayer) **тип padding'а** (`padding`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPy6-6kpmvQK"
   },
   "source": [
    "Какими их берут обычно -- будет показано в примере ниже. По крайней мере, можете стартовать с этих настроек, чтобы понять, какое качество \"из коробки\" будет у простой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "arl2FqAfmvQL"
   },
   "source": [
    "Посмотрим, как работает CNN на MNIST'е и на CIFAR'е:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ly4hPj7DmvQM"
   },
   "source": [
    "<img src=\"http://present5.com/presentation/20143288_415358496/image-8.jpg\" width=500, height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "94s_K_pAmvQN"
   },
   "source": [
    "**MNIST:** это набор из 70k картинок рукописных цифр от 0 до 9, написанных людьми, 60k из которых являются тренировочной выборкой (`train` dataset)), и ещё 10k выделены для тестирования модели (`test` dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 615,
     "status": "error",
     "timestamp": 1541754216636,
     "user": {
      "displayName": "Михаил Владимирович Макаров",
      "photoUrl": "",
      "userId": "00571021236711414160"
     },
     "user_tz": -180
    },
    "id": "O1tqZNdWmvQN",
    "outputId": "dd6c7d19-2350-4b53-de7f-588ca4532d61"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  # для отрисовки картиночек\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kXXOvRS1mvQS"
   },
   "source": [
    "Скачаем и загрузим в `loader`'ы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmCjo8CjmvQT"
   },
   "source": [
    "**Обратите внимание на аргумент `batch_size`:** именно он будет отвечать за размер батча, который будет подаваться при оптимизации нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DpjaLS99mvQV",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 9838592/9912422 [00:20<00:00, 1667564.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\n",
      " 57%|█████▋    | 16384/28881 [00:00<00:00, 88235.60it/s]\n",
      "32768it [00:00, 58540.39it/s]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\n",
      "  1%|          | 16384/1648877 [00:00<00:20, 78997.08it/s]\n",
      "  2%|▏         | 40960/1648877 [00:00<00:17, 89918.47it/s]\n",
      "  6%|▌         | 98304/1648877 [00:00<00:13, 114162.44it/s]\n",
      " 10%|▉         | 163840/1648877 [00:01<00:10, 143261.90it/s]\n",
      " 14%|█▍        | 229376/1648877 [00:01<00:08, 174441.50it/s]\n",
      " 23%|██▎       | 376832/1648877 [00:01<00:05, 228335.77it/s]\n",
      " 35%|███▌      | 581632/1648877 [00:01<00:03, 299649.47it/s]\n",
      " 48%|████▊     | 786432/1648877 [00:01<00:02, 383496.17it/s]\n",
      " 61%|██████    | 1007616/1648877 [00:02<00:01, 480232.23it/s]\n",
      " 75%|███████▌  | 1236992/1648877 [00:02<00:00, 588573.81it/s]\n",
      " 89%|████████▉ | 1474560/1648877 [00:02<00:00, 754654.71it/s]\n",
      " 98%|█████████▊| 1613824/1648877 [00:02<00:00, 866552.37it/s]\n",
      "1654784it [00:02, 664909.76it/s]                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/4542 [00:00<?, ?it/s]\n",
      "8192it [00:00, 19792.11it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, \n",
    "                                      download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                     download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = tuple(str(i) for i in range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqtRMMqwmvQa"
   },
   "source": [
    "Сами данные лежат в полях `trainloader.dataset.train_data` и `testloader.dataset.test_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxnQI-7FmvQc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccord517\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.dataset.train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-rt0UBALmvQf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccord517\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testloader.dataset.test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aj4QmKwDmvQk"
   },
   "source": [
    "Выведем первую картинку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nBAKbazhmvQm",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccord517\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
       "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
       "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
       "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
       "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
       "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
       "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
       "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
       "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
       "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
       "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
       "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9920512it [00:39, 1667564.61it/s]                             "
     ]
    }
   ],
   "source": [
    "trainloader.dataset.train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7YqZYacmvQq"
   },
   "source": [
    "Посмотрим, как она выглядит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SHxq21ydmvQq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccord517\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "# преобразовать тензор в np.array\n",
    "numpy_img = trainloader.dataset.train_data[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lz-SfUuOmvQt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kAxc-OjwmvQy"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2262e084438>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(numpy_img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jo1SInrpmvQ2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2262e0e7978>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(numpy_img, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OW3JZteDmvQ7"
   },
   "source": [
    "Отрисовка заданной цифры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VC-xcS7rmvQ7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccord517\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x226367b87f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# случайный индекс от 0 до размера тренировочной выборки\n",
    "i = np.random.randint(low=0, high=60000)\n",
    "\n",
    "plt.imshow(trainloader.dataset.train_data[i].numpy(), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e9DOvlk1mvRB"
   },
   "source": [
    "Как итерироваться по данным с помощью `loader'`а? Очень просто:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V73spLIAmvRD",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([9, 9, 6, 0])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainloader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5gLVfQsLmvRI"
   },
   "source": [
    "То есть мы имеем дело с кусочками данных размера batch_size (в данном случае = 4), причём в каждом батче есть как объекты, так и ответы на них (то есть и $X$, и $y$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sftGrFWvmvRK"
   },
   "source": [
    "Теперь вернёмся к тому, что в PyTorch есть две \"парадигмы\" построения нейросетей -- `Functional` и `Seuquential`. Со второй мы уже хорошенько разобрались в предыдущих ноутбуках по нейросетям, теперь мы испольузем именно `Functional` парадигму, потому что при построении свёрточных сетей это намного удобнее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjaimqEhmvRM"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JOY8j76OmvRP"
   },
   "outputs": [],
   "source": [
    "# ЗАМЕТЬТЕ: КЛАСС НАСЛЕДУЕТСЯ ОТ nn.Module\n",
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        # вызов конструктора предка\n",
    "        super(SimpleConvNet, self).__init__()\n",
    "        # необходмо заранее знать, сколько каналов у картинки (сейчас = 1),\n",
    "        # которую будем подавать в сеть, больше ничего\n",
    "        # про входящие картинки знать не нужно\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 16, 120)  # !!!\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 4 * 4 * 16)  # !!!\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDc3BlhPmvRR"
   },
   "source": [
    "**Важное примечание:** Вы можете заметить, что в строчках с `#!!!` есть не очень понятный сходу 4 `*` 4 `*` 16. Это -- размерность картинки перед FC-слоями (H x W x C), тут её приходиться высчитывать вручную (в Keras, например, `.Flatten()` всё делает за Вас). Однако есть один *лайфхак* -- просто сделайте в `forward()` `print(x.shape)` (закомментированная строка). Вы увидите размер `(batch_size, C, H, W)` -- нужно перемножить все, кроме первого (batch_size), это и будет первая размерность `Linear()`, и именно в C * H * W нужно \"развернуть\" x перед подачей в `Linear()`.  \n",
    "\n",
    "То есть нужно будет запустить цикл с обучением первый раз с `print()` и сделать после него `break`, посчитать размер, вписать его в нужные места и стереть `print()` и `break`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tyg446camvRS"
   },
   "source": [
    "Код обучения слоя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BtBorLrrmvRT"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ja5vFAvWmvRY",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64ef95d7601499db77962a816b99b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9784e2355ce42aca19e064b4671d9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.065\n",
      "[1,  4000] loss: 0.408\n",
      "[1,  6000] loss: 0.278\n",
      "[1,  8000] loss: 0.241\n",
      "[1, 10000] loss: 0.209\n",
      "[1, 12000] loss: 0.165\n",
      "[1, 14000] loss: 0.159\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b90b8b658d6475d9cad26bd6eec8640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  2000] loss: 0.133\n",
      "[2,  4000] loss: 0.120\n",
      "[2,  6000] loss: 0.121\n",
      "[2,  8000] loss: 0.108\n",
      "[2, 10000] loss: 0.097\n",
      "[2, 12000] loss: 0.089\n",
      "[2, 14000] loss: 0.084\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb2a04054564c2fb73c5ab55cedbd31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  2000] loss: 0.087\n",
      "[3,  4000] loss: 0.084\n",
      "[3,  6000] loss: 0.072\n",
      "[3,  8000] loss: 0.068\n",
      "[3, 10000] loss: 0.080\n",
      "[3, 12000] loss: 0.077\n",
      "[3, 14000] loss: 0.061\n",
      "Обучение закончено\n"
     ]
    }
   ],
   "source": [
    "# объявляем сеть\n",
    "net = SimpleConvNet()\n",
    "\n",
    "# выбираем функцию потерь\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# выбираем алгоритм оптимизации и learning_rate\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# итерируемся\n",
    "for epoch in tqdm_notebook(range(3)):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(tqdm_notebook(trainloader)):\n",
    "        # так получаем текущий батч\n",
    "        X_batch, y_batch = batch\n",
    "        \n",
    "        # обнуляем веса\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        y_pred = net(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выведем текущий loss\n",
    "        running_loss += loss.item()\n",
    "        # выведем качество каждые 2000 батчей\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Обучение закончено')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJ8up_fZmvRc"
   },
   "source": [
    "Протестируем на всём тестовом датасете, используя метрику accuracy_score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJc3Zea2mvRc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of     0 : 99 %\n",
      "Accuracy of     1 : 99 %\n",
      "Accuracy of     2 : 99 %\n",
      "Accuracy of     3 : 98 %\n",
      "Accuracy of     4 : 97 %\n",
      "Accuracy of     5 : 97 %\n",
      "Accuracy of     6 : 98 %\n",
      "Accuracy of     7 : 98 %\n",
      "Accuracy of     8 : 97 %\n",
      "Accuracy of     9 : 96 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        y_pred = net(images)\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_83Wbv_UmvRf"
   },
   "source": [
    "Два свёрточных слоя побили многослойную нейросеть. Не магия ли?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ca7_nhaCmvRg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LPxtwt8DmvRi"
   },
   "source": [
    "### Задача 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2TQgBg3KmvRm"
   },
   "source": [
    "Протестируйте эту нейросеть на отдельных картинках из тестового датасета: напишите функцию, которая принимает индекс картинки в тестовом датасете, отрисовывает её, потом запускает на ней модель (нейросеть) и выводит результат предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UE1hoLa_mvRn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n",
    "i = np.random.randint(low=0, high=10000)\n",
    "\n",
    "def show_pred(i, testloader):\n",
    "\n",
    "    image, label = testloader.dataset[i]\n",
    "\n",
    "    plt.imshow(image.view(28,28).numpy(), cmap='gray');\n",
    "\n",
    "    y_pred = net(image.view(1,1,28,28))\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "\n",
    "    print('predicted - %s, fact - %s'%(predicted.numpy()[0], label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted - 9, fact - 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x226320396a0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_pred(7, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUKgvCXhmvRq"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cr4ftiAGmvRq"
   },
   "source": [
    "<h3 style=\"text-align: center;\"><b>CIFAR10</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i5ndS6LomvRt"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/soumith/ex/gh-pages/assets/cifar10.png\" width=500, height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zxEQYnT9mvRt"
   },
   "source": [
    "**CIFAR10:** это набор из 60k картинок 32х32х3, 50k которых составляют обучающую выборку, и оставшиеся 10k - тестовую. Классов в этом датасете 10: `'plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'`.\n",
    "\n",
    "Скачаем и загрузим в `loader`'ы:\n",
    "\n",
    "**Обратите внимание на аргумент `batch_size`:** именн он будет отвечать за размер батча, который будет подаваться при оптимизации нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KEH8UgeFmvRu",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data\\cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 168689664/169001437 [03:25<00:00, 2331260.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-IxjpMXfmvRy",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CIFAR100' object has no attribute 'train_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-de72878c8cf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'CIFAR100' object has no attribute 'train_data'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "169009152it [03:40, 2331260.00it/s]                               "
     ]
    }
   ],
   "source": [
    "# случайный индекс от 0 до размера тренировочной выборки\n",
    "i = np.random.randint(low=0, high=50000)\n",
    "\n",
    "plt.imshow(trainloader.dataset.train_data[i], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xAUH5D9tmvR0"
   },
   "source": [
    "То есть мы имеем дело с кусочками данных размера batch_size (в данном случае = 4), причём в каждом батче есть как объекты, так и ответы на них (то есть и $X$, и $y$).\n",
    "\n",
    "Данные готовы, мы даже на них посмотрели. **Однако учтите** - при подаче в нейросеть мы будем разворачивать картинку 32х32х3 в строку 1х(32`*`32`*`3) = 1х3072, то есть мы считаем пиксели (значения интенсивности в пикселях) за признаки нашего объекта (картинки).  \n",
    "\n",
    "К делу:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yIzpcJkZmvR2"
   },
   "source": [
    "### Задача 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FEzw5SbZmvR3"
   },
   "source": [
    "Напишите свою свёрточную нейросеть для предсказания на CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "oCVhQM1mmvR3"
   },
   "outputs": [],
   "source": [
    "# ЗАМЕТЬТЕ: КЛАСС НАСЛЕДУЕТСЯ ОТ nn.Module\n",
    "class MyConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        # вызов конструктора предка\n",
    "        super(MyConvNet, self).__init__()\n",
    "        # Ваш код здесь\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ваш код здесь\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yWwW8daBmvR7"
   },
   "source": [
    "Обучим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "e393qPEBmvR7"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EGOjA5ABmvR-"
   },
   "outputs": [],
   "source": [
    "# пример взят из официального туториала: \n",
    "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "net = MyConvNet()\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# итерируемся\n",
    "for epoch in tqdm_notebook(range(3)):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(tqdm_notebook(trainloader)):\n",
    "        # так получаем текущий батч\n",
    "        X_batch, y_batch = batch\n",
    "        \n",
    "        # РАЗВОРАЧИВАЕМ КАРТИНКУ В СТРОКУ\n",
    "        X_batch = X_batch.view(4, -1)\n",
    "\n",
    "        # обнуляем веса\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        y_pred = net(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выведем текущий loss\n",
    "        running_loss += loss.item()\n",
    "        # выводем качество каждые 2000 батчей\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Обучение закончено')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u4doogQbmvSA"
   },
   "source": [
    "Посмотрим на accuracy на тестовом датасете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VEzyCJHXmvSA"
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        y_pred = net(images.view(4, -1))\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4OF55kMmvSE"
   },
   "source": [
    "Как думаете, этого достаточно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F__l8jHsmvSF"
   },
   "source": [
    "### Задача 3  \n",
    "\n",
    "Улучшите свёрточную нейросеть: поэкспериментируйте с архитектурой (количество слоёв, порядок слоёв), с гиперпараметрами слоёв (размеры kernel_size, размеры pooling'а, количество kernel'ов в свёрточном слое) и с гиперпараметрами, указанными в \"Компоненты нейросети\" (см. памятку выше)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "moepyKFemvSG"
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nwz2zvrSmvSJ"
   },
   "source": [
    "(Ожидаемый результат -- скорее всего, сходу Вам не удастся выжать из Вашей сетки больше, чем ~70% accuracy (в среднем по всем классам). Если это что-то в этом районе - Вы хорошо постарались)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BIIpG-8lmvSK"
   },
   "source": [
    "<h3 style=\"text-align: center;\"><b>Полезные ссылки</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxjnt47smvSO"
   },
   "source": [
    "1). *Примеры написания нейросетей на PyTorch (офийиальные туториалы) (на английском): https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#examples  \n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0OoUDBDmvSP"
   },
   "source": [
    "2). ***Один из самых подробных и полных курсов по deep learning на данный момент - это курс Стэнфордского Университета (он вообще сейчас один из лидеров в области ИИ, его выпускники работают в Google, Facebook, Amazon, Microsoft, в стартапах в Кремниевой долине):  http://cs231n.github.io/***  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lfCLur8VmvSR"
   },
   "source": [
    "3). Практически исчерпывающая информация по основам свёрточных нейросетей (из cs231n) (на английском):  \n",
    "\n",
    "http://cs231n.github.io/convolutional-networks/  \n",
    "http://cs231n.github.io/understanding-cnn/  \n",
    "http://cs231n.github.io/transfer-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9cYDmcZxmvSR"
   },
   "source": [
    "4). Видео о Computer Vision от Andrej Karpathy: https://www.youtube.com/watch?v=u6aEYuemt0M"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[seminar]convnet_pytorch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
