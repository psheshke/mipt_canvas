{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[seminar]loss_functions.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"Y_s28YzI8IBD","colab_type":"text"},"cell_type":"markdown","source":["<p style=\"align: center;\"><img src=\"https://static.tildacdn.com/tild6636-3531-4239-b465-376364646465/Deep_Learning_School.png\" width=\"300\"></p>\n","\n","<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"]},{"metadata":{"id":"H3N0Tchv8IBF","colab_type":"text"},"cell_type":"markdown","source":["---"]},{"metadata":{"id":"AxCV20lq8IBH","colab_type":"text"},"cell_type":"markdown","source":["<h2 style=\"text-align: center;\"><b>Типы функций потерь ($loss$) в задачах машинного обучения</b></h2>"]},{"metadata":{"id":"JImai3c78IBJ","colab_type":"text"},"cell_type":"markdown","source":["Когда мы обучаем какой-либо алгоритм машинного обучения, мы должны задать как минимум 3 вещи:  \n","\n","- дать алгоритму **данные**\n","- выбрать алгоритм **оптимизации**\n","- выбрать **функцию потерь ($loss$)**"]},{"metadata":{"id":"3WQmQ-bp8IBK","colab_type":"text"},"cell_type":"markdown","source":["Допустим, что данные уже есть и алгоритм оптимизации выбран. Рассмотрим типы задач машинного обучения и связанные с ними функции потерь."]},{"metadata":{"id":"3NjSX1_F8IBM","colab_type":"text"},"cell_type":"markdown","source":["* Неформальное определение функции потерь:"]},{"metadata":{"id":"sZi9KpuX8IBN","colab_type":"text"},"cell_type":"markdown","source":["***Функция потерь*** -- это функция, которая принимает на вход предсказания модели и истинные значения целевого признака, а возвращает неотрицательное число, характеризующее то, насколько хорошо наша модель предсказывает целевой признак. Функция потерь всегда зависит от задачи (точнее -- от типа предсказываемого признака)."]},{"metadata":{"id":"ah5TjmuL8IBO","colab_type":"text"},"cell_type":"markdown","source":["* Формальное определение:  \n","\n","Функция потерь - это функция $L: V \\times V \\to \\mathbb{R}^+$, где множество $V$ зависит от задачи."]},{"metadata":{"id":"v-KCi0bD8IBP","colab_type":"text"},"cell_type":"markdown","source":["Рассмотрим 3 задачи:  \n","- задача регрессии ($y \\in \\mathbb{R}$)\n","- бинарная классификация (на 2 класса)  \n","- многоклассовая классификация (на $K$ классов)  "]},{"metadata":{"id":"_dyxOuM98IBR","colab_type":"text"},"cell_type":"markdown","source":["**Чем лучше предсказывает модель, тем меньше значеия функции потерь. Чем модель хуже, тем значения функции потерь больше.**"]},{"metadata":{"id":"4rI7H6r48IBS","colab_type":"text"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Задача регрессии</b></h3>"]},{"metadata":{"id":"16hFIp2f8IBT","colab_type":"text"},"cell_type":"markdown","source":["В задачах регрессии выделяют две основные функции потерь:"]},{"metadata":{"id":"VbZwAJ4D8IBU","colab_type":"text"},"cell_type":"markdown","source":["1). **Квадратичная функция потерь**:  \n","\n","$$L(\\hat{y}, y) = (\\hat{y} - y)^2, ~~~~~\\hat{y}, y \\in \\mathbb{R}$$\n","\n","Если записывать для всей выборки $(X, y)$, где $X$ -- матрица объекты-принаки размера $(n, m)$, а y - столбец истинных ответов размера $(n, 1)$, то:\n","\n","$$L(\\hat{y}, y) = \\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2$$\n","\n","-- в этом случае её ещё называют **среднеквадратичная ошибка (Mean Squared Error (MSE, MSELoss))**."]},{"metadata":{"id":"sZ1AXnsf8IBV","colab_type":"text"},"cell_type":"markdown","source":["2). **Абсолютная функция потерь**:  \n","\n","$$L(\\hat{y}, y) = |\\hat{y} - y|, ~~~~~\\hat{y}, y \\in \\mathbb{R}$$\n","\n","Если записывать для всей выборки $(X, y)$, где $X$ -- матрица объекты-принаки размера $(n, m)$, а y - столбец истинных ответов размера $(n, 1)$, то:\n","\n","$$L(\\hat{y}, y) = \\frac{1}{n} \\sum_{i=1}^n |\\hat{y}_i - y_i|$$\n","\n","-- в этом случае её ещё называют **средняя абсолютная ошибка (Mean Absolute Error (MAE, MAELoss))**."]},{"metadata":{"id":"Tgs7Vfj68IBW","colab_type":"text"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Бинарная классификация</b></h3>"]},{"metadata":{"id":"9hQ8Gd5h8IBX","colab_type":"text"},"cell_type":"markdown","source":["В задачах бинарной классификации иногда тоже используют среднеквадратичную ошибку, однако, например, когда в качестве модели будет выступать *нейрон с сигмоидой (= логистическая регрессия)*, будут некоторые проблемы (см. ноутбук [nn]neuron_logloss.ipynb), поэтому чаще всё-таки используют так называемый $LogLoss$ (или логистическая функция потерь):  \n","\n","$$L(\\hat{y}, y) = -\\frac{1}{n} \\sum_{i=1}^n y_i \\log(\\hat{y_i}) + (1 - y_i) \\log(1 - \\hat{y_i}))$$"]},{"metadata":{"id":"PAkv227Y8IBZ","colab_type":"text"},"cell_type":"markdown","source":["(тут записано уже сразу по всей выборке)."]},{"metadata":{"id":"N0ydE2By8IBa","colab_type":"text"},"cell_type":"markdown","source":["$LogLoss$ чаще всего используют в случае, когда в качестве $\\hat{y}_i$ мы предсказываем вероятность принадлежности к одному из классов, а $y_i \\in \\{0, 1\\}$."]},{"metadata":{"id":"Iykjmalr8IBb","colab_type":"text"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Многоклассовая классификация</b></h3>"]},{"metadata":{"id":"v8zlZCvA8IBd","colab_type":"text"},"cell_type":"markdown","source":["Сначала вспомним, как кодируют целевую переменную в случае многоклассовой классификации.  "]},{"metadata":{"id":"K_KKnCuB8IBe","colab_type":"text"},"cell_type":"markdown","source":["Изначально целевой переменной $y$ (классом, который хотим предсказать) может быть и вовсе какая-нибудь строка ('cat', 'dog', 'human'). Такие метки и признаки называют **категориальными**. В этом случае стоит закодировать $y$ просто последовательными неотрицательными числами:  \n","\n","'cat' $\\to$ 0  \n","'dog' $\\to$ 1  \n","'human' $\\to$ 2  \n","\n","В случае $K$ классов будет $K$ различных числовых значений. Это называется ***LabelEncoding*** (перевод категорий в числовые метки)."]},{"metadata":{"id":"YoEG2nEI8IBh","colab_type":"text"},"cell_type":"markdown","source":["Однако заметим, что такое LabelEncoding задаёт на классах **отношение порядка**, то есть мы, например, можем сказать, что 'human' (2) > 'cat' (0) в данном случае. Это неправильно, поскольку это сравнение некорректно и может привести к непредсказуемымому результату."]},{"metadata":{"id":"7Ye6P0DZ8IBi","colab_type":"text"},"cell_type":"markdown","source":["Поэтому после LabelEncoding'а всегда применяют ***OneHotEncoding***:  \n","\n","0 $\\to$ (1, 0, 0)  \n","1 $\\to$ (0, 1, 0)  \n","2 $\\to$ (0, 0, 1)"]},{"metadata":{"id":"wi5vxEJ_8IBj","colab_type":"text"},"cell_type":"markdown","source":["То есть преобразуют числовое значение класса в строку размера $(1, K)$, где $K$ -- количество классов (в данном случае их 3, поэтому строка длины 3)."]},{"metadata":{"id":"Pu-CD_MU8IBl","colab_type":"text"},"cell_type":"markdown","source":["Тогда предобработка категориальной метки  $y$ такая: \n","- изначальный **столбец меток $y$ размера $(n, 1)$** переходит в **столбец чисел $y_{LabelEncoded}$ размера $(n, 1)$** \n","- столбец $y_{LabelEncoded}$ переходит **в матрицу из 0 и 1 $y_{OneHotEncoded}$ размера $(n, K)$** "]},{"metadata":{"id":"D8LjmWam8IBp","colab_type":"text"},"cell_type":"markdown","source":["С $\\hat{y}$ -- предсказаниями модели -- та же ситуация, только обычно предсказываются сначала вероятности принадлежности к каждому из классов, а потом уже среди них берётся наибольшая и на её месте ставится 1 в строке, а на месте остальных вероятностей ставится 0."]},{"metadata":{"id":"UqbcQfBt8IBr","colab_type":"text"},"cell_type":"markdown","source":["---"]},{"metadata":{"id":"Qz0n44hS8IBv","colab_type":"text"},"cell_type":"markdown","source":["*Небольшое отступление про Softmax*: как, имея строку значений $(a_1, a_2, ..., a_K)$, привести все их значения к диапазону $[0, 1]$ так, чтобы в сумме они давали единицу (то есть чтобы можно было интерпретровать значения как вероятности)? Для этого существует (один из способов) функция под названием $Softmax$:  \n","\n","$$Softmax((a_1, a_2, ..., a_K))_i = \\frac{e^{a_i}}{\\sum_{j=1}^K e^{a_j}}$$"]},{"metadata":{"id":"YXNDj2Gi8IBz","colab_type":"text"},"cell_type":"markdown","source":["**Упражение:** убедитесь, что сумма этих значений будет давать в сумме единицу."]},{"metadata":{"id":"uvAvDQse8IB2","colab_type":"text"},"cell_type":"markdown","source":["То есть строка $(a_1, a_2, ..., a_K)$ переходит в строку:  \n","\n","$$(a_1, a_2, ..., a_K) \\to \\left(\\frac{e^{a_1}}{\\sum_{j=1}^K e^{a_j}}, \\frac{e^{a_2}}{\\sum_{j=1}^K e^{a_j}}, ..., \\frac{e^{a_K}}{\\sum_{j=1}^K e^{a_j}}\\right)$$"]},{"metadata":{"id":"xNH8vr778IB3","colab_type":"text"},"cell_type":"markdown","source":["---"]},{"metadata":{"id":"95U2Q_bh8IB4","colab_type":"text"},"cell_type":"markdown","source":["В задаче многоклассовой классификации чаще всего пользуются функцией под названиаем $CrossEntropy$ -- кросс-энтропия:  \n","\n","$$L(\\hat{y}, y) = -\\frac{1}{n} \\sum_{i=1}^n \\sum_{j=1}^K y_{ij} \\log(\\hat{y_{ij}})$$  \n","\n","где $y$ -- матрица $(n, K)$ истинных значений классов объектов (закодированная OneHot'ом), а $\\hat{y}$ -- матрица $(n, K)$ предсказаний модели ($\\hat{y}_{ij}$ -- \"вероятность\" принадлежности $i$-го объекта к $j$-му классу)"]},{"metadata":{"id":"EE9rqaND8IB5","colab_type":"text"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Важно</b></h3>"]},{"metadata":{"id":"IsZcpo1J8IB6","colab_type":"text"},"cell_type":"markdown","source":["В данном ноутбуке перечислены далеко не все функции потерь и описаны далеко не все задачи машинного обучения, а лишь 3 конкретных. Более подробно про функции потерь в других задачах и об ML в целом можно больше узнать на курсах, таких, как, например, [курс Воронцова К.В.](https://www.youtube.com/playlist?list=PLJOzdkh8T5kp99tGTEFjH_b9zqEQiiBtC)."]},{"metadata":{"id":"I0njZv2u8IB7","colab_type":"text"},"cell_type":"markdown","source":["<h3 style=\"text-align: center;\"><b>Полезные ссылки</b></h3>"]},{"metadata":{"id":"HAINFtXX8IB8","colab_type":"text"},"cell_type":"markdown","source":["1). [Вики-страничка по функциям потерь](http://ru.learnmachinelearning.wikia.com/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D0%BF%D0%BE%D1%82%D0%B5%D1%80%D1%8C_(Loss_function) (информации немного, но зато упомянуты другие функции потерь)"]},{"metadata":{"id":"rUtqypey8IB9","colab_type":"text"},"cell_type":"markdown","source":["2). Github с очень большим количеством полезных материалов по Machine Learning: https://github.com/demidovakatya/vvedenie-mashinnoe-obuchenie"]}]}