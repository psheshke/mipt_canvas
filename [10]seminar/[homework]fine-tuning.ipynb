{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dBco-TbRVBRJ"
   },
   "source": [
    "<p style=\"align: center;\"><img src=\"https://static.tildacdn.com/tild6636-3531-4239-b465-376364646465/Deep_Learning_School.png\", width=300, height=300></p>\n",
    "\n",
    "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>\n",
    "\n",
    "--- \n",
    "# [kaggle] Классификация дорожных знаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LtHS_3mjVBRK"
   },
   "source": [
    "# Использование предобученных нейросетей (transfer learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PBD_kAlcVBRL"
   },
   "source": [
    "### В этом ноутбуке вам предлагается посоревноваться в классификации дорожных знаков Швеции. \n",
    "Вики: https://commons.wikimedia.org/wiki/Road_signs_in_Sweden \n",
    "\n",
    "Kaggle: https://www.kaggle.com/c/sweden-traffic-signs-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PQsTsDi3VBRL"
   },
   "source": [
    "Существует распространённый и очень эффективный подход к обучению глубоких нейросетей на маленьком датасете изображений. Можно использовать предобученную нейросеть. Предобученная нейросеть - это нейросеть с сохранёнными весами, которая была обучена на большом датасете, обычно на действительно большом объёме данных вроде ImageNet. Если этот оригинальный датасет достаточно большой и исчерпывающий, то пространственная иерархия фичей, выученная нейросетью может быть использована как обобщённая модель визуального мира, и, таким образом, эти фичи могут быть полезны в разных задачах машинного зрения, хотя новые задачи могут иметь совершенно другие классы, чем в оригинальном датасете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dWouqbKJVBRM"
   },
   "source": [
    "Например, обучив нейросеть на ImageNet (где классы в основном животные и бытовые объекты), её можно использовать в задаче с совершенно другими доменами, к примеру, нахождение мебели на изображениях. Такая переносимость выученных фичей на разные задачи есть ключевое преимущество глубинного обучения над классическими подходами. И это делает глубинное обучение крайне эффективным на задачах с \"маленькими\" данными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oW9eNglfVBRN"
   },
   "source": [
    "Существует два подхода к использованию предобученных сетей: **feature extraction (извлекатель фичей)** and **fine-tuning (тонкая настройка)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ixbaFfpVBRN"
   },
   "source": [
    "*Дополнительно:*  \n",
    "* в этой статье рассказывается о классификации знаков и как улучшить скор, но код под TensorFlow :P  \n",
    " https://navoshta.com/traffic-signs-classification/\n",
    "* а вот здесь можно достать **много** (в 15 раз больше, чем у нас) данных как раз о дорожных знаках, но из Германии.  \n",
    "https://www.kaggle.com/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign/  \n",
    "\n",
    "Попробуйте разные подходы, имея в распоряжении [этот датасет](https://www.kaggle.com/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign/):\n",
    " 1. обучите на нём нейросеть из семинара №9 или любую из [известных архитектур](https://pytorch.org/docs/stable/torchvision/models.html)\n",
    " 2. предсказывайте похожие классы напрямую (знаки ограничения скорости 90)  \n",
    " 3. fine-tuning сети, обученной на дорогах Германии под дороги Швеции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8aix_yrVBRO"
   },
   "source": [
    "## Ниже предоставлен base-line для соревнования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3i0TS1SfVBRP"
   },
   "source": [
    "Это простой классификатор(CNN) из семинара №9, т.е. **предобученные сети не использованы**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S6fzViB2VBRP"
   },
   "source": [
    "Вам предлагается используя код и материалы с семинара достичь лучших результатов и вырваться в лидеры нашего kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3VHDyVeVBRQ"
   },
   "outputs": [],
   "source": [
    "# Установим размер классифицируемых изображений\n",
    "PIC_SIZE = 50\n",
    "# Путь к предобработанным данным\n",
    "data_path = 'data//'\n",
    "# Путь, куда сохраним модель\n",
    "model_save_path = 'signs_classifier.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "loS9vS_bVBRT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Версия torch', torch.__version__)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NxQSPe_YVBRV"
   },
   "source": [
    "Ноутбук создан под версией torch '1.0.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-ouX9TtVBRV"
   },
   "source": [
    "### Создадим класс-обёртку для нашего датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "braR7MNKVBRW"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SignsDataset(Dataset):\n",
    "    \"\"\"Road signs dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, no_labels=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.signs_frame = pd.read_csv(csv_file)\n",
    "        print(f'{len(self.signs_frame)} samples loaded')\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.no_labels = no_labels\n",
    "        \n",
    "        # В тестовом датасете нет ответов\n",
    "        if not self.no_labels:\n",
    "            # Cоздаём массив label->index и массив index->label\n",
    "            self.labels = self.signs_frame['label'].unique()\n",
    "            self.label_indexes = {}\n",
    "            for i, label in enumerate(self.labels):\n",
    "                self.label_indexes[label] = i\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signs_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Загрузим изображение и приведём к размеру 50х50\n",
    "        img_name = self.root_dir + self.signs_frame.iloc[idx, 0]\n",
    "        image = Image.open(img_name)\n",
    "        image = image.resize((PIC_SIZE, PIC_SIZE), Image.ANTIALIAS)\n",
    "        \n",
    "        # Применим преобразования изображения (например аугментацию)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Для тестового датасета не нужны ответы\n",
    "        if not self.no_labels:\n",
    "            # В роли ответа будем давать номер label\n",
    "            label_string = self.signs_frame.iloc[idx, 1]\n",
    "            label = self.label_indexes[label_string]\n",
    "        \n",
    "            sample = {'image': image, 'label': label}\n",
    "        else:\n",
    "            sample = {'image': image}\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2GbgtqEsVBRY"
   },
   "source": [
    "### Создадим DataLoader'ы, облегчающие закрузку и сэмплинг данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GdcM8hClVBRY"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Инициализируем загрузчик датасета (класс выше)\n",
    "dataset = SignsDataset(data_path + 'train.csv', \n",
    "                       data_path + 'data//', \n",
    "                       torchvision.transforms.ToTensor())\n",
    "\n",
    "indicies = np.arange(len(dataset))\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(indicies)\n",
    "\n",
    "# Разбиение датасета на train и validation\n",
    "train_sampler = SubsetRandomSampler(indicies[:int(len(dataset)*0.5)])\n",
    "validation_sampler = SubsetRandomSampler(indicies[int(len(dataset)*0.5):])\n",
    "\n",
    "# DataLoader достаёт данные из dataset батчами\n",
    "signsTrainLoader = DataLoader(dataset, batch_size=16, sampler=train_sampler)\n",
    "signsValidationLoader = DataLoader(dataset, batch_size=32, sampler=validation_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1YD8HcoaVBRa"
   },
   "outputs": [],
   "source": [
    "# Посмотрим, что выдаёт одна итерация DataLoader\n",
    "batch = next(iter(signsTrainLoader))\n",
    "img = batch['image'][0]\n",
    "img = np.transpose(img, (1, 2, 0))\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YSkqTLpVBRe"
   },
   "source": [
    "### Данные сильно несбалансированы (unbalanced dataset)\n",
    "### Задача\n",
    "    Взгляните на количество представителей каждого класса \n",
    "    К чему это может привести?\n",
    "    \n",
    "    Подумайте о вариантах исправления проблемы\n",
    "#### upsampling, аугментация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_aPODa0VBRe"
   },
   "outputs": [],
   "source": [
    "df = dataset.signs_frame\n",
    "classes_number = df['label'].nunique()\n",
    "print('Classes number:', classes_number)\n",
    "df.groupby('label')['file_name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lLmHhzunVBRg"
   },
   "source": [
    "## Создаём и обучаем сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uv8_ByrhVBRh"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GnCMgXIGVBRi"
   },
   "outputs": [],
   "source": [
    "# Класс свёрточной нейронной сети\n",
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self, class_number):\n",
    "        # вызов конструктора предка\n",
    "        super(SimpleConvNet, self).__init__()\n",
    "        # необходмо заранее знать, сколько каналов у картинки (сейчас = 3),\n",
    "        # которую будем подавать в сеть, больше ничего\n",
    "        # про входящие картинки знать не нужно\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 9 * 9, 120)  # !!! \n",
    "        \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, class_number)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Подаём картинку на вход и увидим, сколько элементов на входе первого fully connected!\n",
    "        # Подробнее замечание снизу (оно из прошлого семинара)\n",
    "        # print(x.shape)\n",
    "        ## ИЛИ ЖЕ МОЖНО ЭТО РАССЧИТАТЬ, НО ЭТО ДОЛЬШЕ\n",
    "        \n",
    "        x = x.view(-1, 16 * 9 * 9)  # !!! Аналог Flatten в keras\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        # Функция акктивации отсутствует\n",
    "        # torch.nn.CrossEntropyLoss разбирается с этим сам\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTd5QlKpVBRk"
   },
   "source": [
    "#### Примечание из прошлого семинара"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWNbf8aIVBRk"
   },
   "source": [
    "Важное примечание: Вы можете заметить, что в строчках с #!!! есть не очень понятный сходу $9 * 9 * 16$. Это -- размерность картинки перед FC-слоями (H x W x C), тут её приходиться высчитывать вручную (в Keras, например, .Flatten() всё делает за Вас). Однако есть один лайфхак -- просто сделайте в forward() print(x.shape) (закомментированная строка). Вы увидите размер (batch_size, C, H, W) -- нужно перемножить все, кроме первого (batch_size), это и будет первая размерность Linear(), и именно в C H W нужно \"развернуть\" x перед подачей в Linear().\n",
    "\n",
    "То есть нужно будет запустить цикл с обучением первый раз с print() и сделать после него break, посчитать размер, вписать его в нужные места и стереть print() и break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPi6fn26VBRl"
   },
   "outputs": [],
   "source": [
    "# Создаём сеть\n",
    "cnn = SimpleConvNet(classes_number).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zyP1gCLMVBRm"
   },
   "outputs": [],
   "source": [
    "# Взглянем на вывод\n",
    "batch = next(iter(signsTrainLoader))\n",
    "cnn(batch['image'].to(device))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWCWYFj8VBRo"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# С помощью этого увидим, как сеть обучалась\n",
    "history = {'loss':[], 'val_loss':[]}\n",
    "\n",
    "# Выбираем функцию потерь\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Выбираем алгоритм оптимизации и learning_rate\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "# Цикл обучения\n",
    "i = 0\n",
    "for epoch in tqdm_notebook(range(100)):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for batch in signsTrainLoader:\n",
    "        \n",
    "        # Так получаем текущий батч\n",
    "        X_batch, y_batch = batch['image'].to(device), batch['label'].to(device)\n",
    "        \n",
    "        # Обнуляем веса\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        y_pred = cnn(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Выведем текущий loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Пишем в лог каждые 50 батчей\n",
    "        if i % 50 == 49:\n",
    "            batch = next(iter(signsValidationLoader))\n",
    "            X_batch, y_batch = batch['image'].to(device), batch['label'].to(device)\n",
    "            y_pred = cnn(X_batch)\n",
    "            \n",
    "            history['loss'].append(loss.item())\n",
    "            history['val_loss'].append(loss_fn(y_pred, y_batch).item())\n",
    "        \n",
    "        # Выведем качество каждые 1000 батчей\n",
    "        if i % 1000 == 999:\n",
    "            print('[%d, %5d] loss: %.4f' % (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0\n",
    "        i += 1\n",
    "\n",
    "# Сохраним модель\n",
    "torch.save(cnn.state_dict(), model_save_path)\n",
    "print('Обучение закончено')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NE18DvTxVBRq"
   },
   "source": [
    "### Начертим кривые обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k15KsSqzVBRq"
   },
   "outputs": [],
   "source": [
    "# Скользящее среднее\n",
    "def smooth_curve(points, factor=0.9):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "\n",
    "plt.clf()\n",
    "loss_values = smooth_curve(history['loss'])\n",
    "val_loss_values = smooth_curve(history['val_loss'])\n",
    "epochs = np.arange(len(loss_values))\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i14Zvq6wVBRs"
   },
   "source": [
    "### Выведем confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNrEqEJzVBRs"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "    \n",
    "# Воспользуемся функцией из документации matplotlib, выводящей confusion matrix \n",
    "# Source https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html    \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    cm = cm.T\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "    plt.figure(figsize=(16,11))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wQJzwM8IVBRu",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_test_all = torch.Tensor().long()\n",
    "predictions_all = torch.Tensor().long()\n",
    "\n",
    "# Пройдём по всему validation датасету и запишем ответы сети\n",
    "with torch.no_grad():\n",
    "    for batch in signsValidationLoader:\n",
    "        predictions = cnn(batch['image'].to(device))\n",
    "        y_test = batch['label']\n",
    "        _, predictions = torch.max(predictions.cpu(), 1)\n",
    "        \n",
    "        # Аналог append для list\n",
    "        y_test_all = torch.cat((y_test_all, y_test), 0)\n",
    "        predictions_all = torch.cat((predictions_all, predictions), 0)\n",
    "\n",
    "feature_names = signsTrainLoader.dataset.labels\n",
    "\n",
    "y_test_all = y_test_all.numpy()\n",
    "predictions_all = predictions_all.numpy()\n",
    "\n",
    "# Функция из sklearn, создаёт confusion матрицу\n",
    "cm = confusion_matrix(y_test_all, predictions_all, np.arange(classes_number))\n",
    "# Выведем её\n",
    "plot_confusion_matrix(cm, dataset.labels, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XbgfMskFVBRx"
   },
   "source": [
    "### Задача\n",
    "    - какие выводы можно сделать из confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ikJnhGIAVBRy"
   },
   "source": [
    "### Выведем точность для каждого класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEvv7PNFVBRy",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_correct = [0 for i in range(classes_number)]\n",
    "class_total = [0 for i in range(classes_number)]\n",
    "\n",
    "c = (predictions_all == y_test_all).squeeze()\n",
    "for i in range(len(predictions_all)):\n",
    "    label = predictions_all[i]            \n",
    "    class_correct[label] += c[i].item()\n",
    "    class_total[label] += 1\n",
    "\n",
    "print(class_total)\n",
    "\n",
    "for i in range(classes_number):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        (dataset.labels[i], (100 * class_correct[i] / class_total[i]) if class_total[i] != 0 else -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LtRrhmE2VBR0"
   },
   "source": [
    "### Задача\n",
    "    - какая связь между confusion matrix и accuracy для каждого класса?\n",
    "    \n",
    "#### Числа на диагонали confusion matrix и есть эти accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iKDujWxJVBR0"
   },
   "source": [
    "### Оценим качество на отдельных кадрах из validation'а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A0HUoG3wVBR1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch = next(iter(signsValidationLoader))\n",
    "predictions = cnn(batch['image'].to(device))\n",
    "y_test = batch['label']\n",
    "\n",
    "\n",
    "#print(predictions, y_test)\n",
    "_, predictions = torch.max(predictions, 1)\n",
    "\n",
    "img = batch['image'][0]\n",
    "img = np.transpose(img, (1, 2, 0))\n",
    "plt.imshow(img)\n",
    "\n",
    "print('Gound-true:', dataset.labels[batch['label'][0]])\n",
    "print('Prediction:', dataset.labels[predictions[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BjKQy6O6VBR2"
   },
   "source": [
    "# Генерация файла ответов на test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pW35-M3hVBR3"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Инициализируем загрузчик датасета (класс выше)\n",
    "test_dataset = SignsDataset(data_path + 'test.csv', \n",
    "                       data_path + 'data//', \n",
    "                       torchvision.transforms.ToTensor(),\n",
    "                       no_labels=True)\n",
    "\n",
    "\n",
    "# DataLoader достаёт данные из dataset батчами\n",
    "signsTestLoader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pz59HPwrVBR4"
   },
   "outputs": [],
   "source": [
    "answer = []\n",
    "\n",
    "for batch in signsTestLoader:\n",
    "    predictions = cnn(batch['image'].to(device))\n",
    "    _, predictions = torch.max(predictions, 1)\n",
    "    answer.append(dataset.labels[predictions[0]])    \n",
    "\n",
    "prediction_df = test_dataset.signs_frame\n",
    "    \n",
    "prediction_df['label'] = pd.Series(answer)\n",
    "prediction_df.to_csv('my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EXXae6PwVBR6"
   },
   "source": [
    "# Полезные ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZLkds10mVBR6"
   },
   "source": [
    "Лучшее руководство по matplotlib: https://matplotlib.org/faq/usage_faq.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hbc0QrGRVBR7"
   },
   "source": [
    "Автор: Мурашов Леонид"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "[homework]fine-tuning.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
